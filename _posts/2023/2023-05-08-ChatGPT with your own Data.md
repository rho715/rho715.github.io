---
layout: single
title: "ChatGPT with your own Data"
categories: [OpenAI]
tag: [ChatGPT]
toc: false
author_profile: false
sidebar:
    nav: "docs"
search: true
---

1. [RAG](https://github.com/Azure-Samples/azure-search-openai-demo/tree/main)
2. [Azure/azure-openai-samples](https://github.com/Azure/azure-openai-samples/tree/main)
    - Quick Start 
    - Fundamentals 
    - Use Cases 
    - Sample Solutions 
    - Serverless SQL GPT 
3. [openai/openai-cookbook](https://github.com/openai/openai-cookbook/tree/main)
    - examples
        - Question_answering_using_embeddings.ipynb
        - Embedding_long_inputs.ipynb
        - Semantic_text_search_using_embeddings.ipynb

4. [style](https://betterprogramming.pub/how-to-give-your-chatbot-the-power-of-neural-search-with-openai-ebcff5194170)
    - [github](https://github.com/amoghagastya/semantic-search-demo/blob/main/%F0%9F%92%AC_Demo.py)
    - [colab](https://colab.research.google.com/drive/1Vr1JOV57zt5JXQbDwPSfdEk6c4L5Zot6?usp=sharing#scrollTo=SO6FcG1Vvoz_)
    - [demo](https://github.com/amoghagastya/semantic-search-demo/blob/main/%F0%9F%92%AC_Demo.py)

5. [toggle](https://blog.streamlit.io/ai-talks-chatgpt-assistant-via-streamlit/)
6. [Tokenizer](https://platform.openai.com/tokenizer)
7. [Prompt Engineering]()
    - [Prompt-Engineering-Guide: github](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-lecture.ipynb)
    - [promptingguide.ai](https://www.promptingguide.ai/)
## [Revolutionize your Enterprise Data with ChatGPT: Next-gen Apps w/ Azure OpenAI and Cognitive Search](https://techcommunity.microsoft.com/t5/ai-applied-ai-blog/revolutionize-your-enterprise-data-with-chatgpt-next-gen-apps-w/ba-p/3762087)

### Chatting with your own data 
1. One approach to have ChatGPT generate responses based on your own data is simple: inject this information into the prompt. 
2. This presents a new challenge though: these models have a limit on the “context length” they support (the current ChatGPT model can take up to 4000 tokens in a prompt), and even if they didn’t have those limits, it wouldn’t be practical to inject GBs worth of data into a text prompt in each interaction. 
3. 


## 